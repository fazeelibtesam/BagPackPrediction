{"metadata":{"kernelspec":{"display_name":"Python [conda env:base] *","language":"python","name":"conda-base-py"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.7"},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Import Libraries","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_squared_error\nimport matplotlib.pyplot as plt\nimport seaborn as sns","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Load the Data","metadata":{}},{"cell_type":"code","source":"# Load the training and test datasets\ntrain_data = pd.read_csv('train.csv')  # Replace with your training data file path\ntest_data = pd.read_csv('test.csv')    # Replace with your test data file path\n\n# Display the first few rows of the training data\ntrain_data.head()","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Handling missing values","metadata":{}},{"cell_type":"code","source":"print(\"Missing values in training data:\")\nprint(train_data.isnull().sum())\n\nprint(\"\\nMissing values in test data:\")\nprint(test_data.isnull().sum())","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Fill missing values in training data\nfor column in ['Brand', 'Material', 'Size', 'Laptop Compartment', 'Waterproof', 'Style', 'Color']:\n    train_data[column].fillna(train_data[column].mode()[0], inplace=True)  # Fill with mode for categorical columns\n\n#train_data['Weight Capacity (kg)'].fillna(train_data['Weight Capacity (kg)'].mean(), inplace=True)  # Fill with mean for numerical column\n\n# Fill missing values in test data\nfor column in ['Brand', 'Material', 'Size', 'Laptop Compartment', 'Waterproof', 'Style', 'Color']:\n    test_data[column].fillna(test_data[column].mode()[0], inplace=True)  # Fill with mode for categorical columns\n\n#test_data['Weight Capacity (kg)'].fillna(test_data['Weight Capacity (kg)'].mean(), inplace=True)  # Fill with mean for numerical column\n\n# Check for missing values again\nprint(\"Missing values in training data after filling:\")\nprint(train_data.isnull().sum())\n\nprint(\"\\nMissing values in test data after filling:\")\nprint(test_data.isnull().sum())","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# before encoding ","metadata":{}},{"cell_type":"code","source":"print(\"Training Data Columns:\")\nprint(train_data.columns)\n\nprint(\"\\nTest Data Columns:\")\nprint(test_data.columns)","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Standardize column names\ntrain_data.columns = train_data.columns.str.lower().str.strip()\ntest_data.columns = test_data.columns.str.lower().str.strip()","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Encoding Categorical Variables","metadata":{}},{"cell_type":"code","source":"# Encode categorical variables\nlabel_encoders = {}\nfor column in ['brand', 'material', 'size', 'compartments', 'laptop compartment', 'waterproof', 'style', 'color']:\n    le = LabelEncoder()\n    train_data[column] = le.fit_transform(train_data[column])\n    test_data[column] = le.transform(test_data[column])\n    label_encoders[column] = le","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Splitting the dataset","metadata":{}},{"cell_type":"code","source":"# Define features and target variable\nX = train_data.drop(columns=['id', 'price'])\ny = train_data['price']\n\n# Split the training data into training and validation sets\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# training the model","metadata":{}},{"cell_type":"code","source":"# Initialize and train the model\nmodel = RandomForestRegressor(n_estimators=100, random_state=42)\nmodel.fit(X_train, y_train)\n\n# Make predictions on the validation set\ny_pred = model.predict(X_val)\n\n# Evaluate the model\nmse = mean_squared_error(y_val, y_pred)\nprint(f'Mean Squared Error: {mse}')","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# hyperparameter","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\nparam_grid = {\n    'n_estimators': [50, 100, 200],\n    'max_depth': [None, 10, 20, 30],\n    'min_samples_split': [2, 5, 10]\n}\n\ngrid_search = GridSearchCV(RandomForestRegressor(), param_grid, cv=5, scoring='neg_mean_squared_error')\ngrid_search.fit(X_train, y_train)\n\nprint(\"Best parameters found: \", grid_search.best_params_)","metadata":{"scrolled":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Train the Model with Best Parameters","metadata":{}},{"cell_type":"code","source":"# Create a new RandomForestRegressor with the best parameters\nbest_model = RandomForestRegressor(\n    n_estimators=grid_search.best_params_['n_estimators'],\n    max_depth=grid_search.best_params_['max_depth'],\n    min_samples_split=grid_search.best_params_['min_samples_split'],\n    random_state=42\n)\n\n# Fit the model to the training data\nbest_model.fit(X_train, y_train)","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#  Evaluate the Model","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Assuming `best_model` is the model obtained after hyperparameter tuning\ny_val_pred = best_model.predict(X_val)\n\n# Calculate evaluation metrics\nmae = mean_absolute_error(y_val, y_val_pred)\nmse = mean_squared_error(y_val, y_val_pred)\nr2 = r2_score(y_val, y_val_pred)\n\n# Print the results\nprint(f'Mean Absolute Error (MAE): {mae:.2f}')\nprint(f'Mean Squared Error (MSE): {mse:.2f}')\nprint(f'R-squared (RÂ²): {r2:.2f}')","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Cross Validation","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import cross_val_score\n\nscores = cross_val_score(model, X, y, cv=5, scoring='neg_mean_squared_error')\nprint(\"Cross-validated MSE: \", -scores.mean())","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Get feature importances\nimportances = best_model.feature_importances_\nfeatures = X.columns\n\n# Create a DataFrame for visualization\nimportance_df = pd.DataFrame({'Feature': features, 'Importance': importances})\nimportance_df = importance_df.sort_values(by='Importance', ascending=False)\n\n# Plot feature importances\nplt.figure(figsize=(10, 6))\nsns.barplot(x='Importance', y='Feature', data=importance_df)\nplt.title('Feature Importances')\nplt.show()","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# visualization","metadata":{}},{"cell_type":"code","source":"# Visualize the feature importances\nfeature_importances = model.feature_importances_\nfeatures = X.columns\nimportance_df = pd.DataFrame({'Feature': features, 'Importance': feature_importances})\nimportance_df = importance_df.sort_values(by='Importance', ascending=False)\n\nplt.figure(figsize=(10, 6))\nsns.barplot(x='Importance', y='Feature', data=importance_df)\nplt.title('Feature Importances')\nplt.show()","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Confusion Matrix","metadata":{}},{"cell_type":"code","source":"# Define price bins\nbins = [0, 50, 100, 150, 200]  # Adjust these values based on your data\nlabels = ['Low', 'Medium', 'High', 'Very High']\n\n# Create a new column in the training and validation sets for the price category\ntrain_data['price_category'] = pd.cut(train_data['price'], bins=bins, labels=labels)\ny_val_category = pd.cut(y_val, bins=bins, labels=labels)","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Make predictions on the validation set\ny_pred = model.predict(X_val)\n\n# Convert predictions to categories\ny_pred_category = pd.cut(y_pred, bins=bins, labels=labels)","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix, f1_score, accuracy_score\n\n# Calculate confusion matrix\nconf_matrix = confusion_matrix(y_val_category, y_pred_category)\n\n# Calculate F1 score\nf1 = f1_score(y_val_category, y_pred_category, average='weighted')\n\n# Calculate accuracy\naccuracy = accuracy_score(y_val_category, y_pred_category)\n\n# Print the results\nprint(\"Confusion Matrix:\")\nprint(conf_matrix)\nprint(f\"F1 Score: {f1:.2f}\")\nprint(f\"Accuracy: {accuracy:.2f}\")","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Make predictions on the test set\ntest_predictions = model.predict(test_data.drop(columns=['id']))\n\n# Create a DataFrame for the predictions\npredictions_df = pd.DataFrame({\n    'id': test_data['id'],\n    'predicted_price': test_predictions\n})\n\n# Save predictions to a CSV file\npredictions_df.to_csv('predicted_prices.csv', index=False)","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import GradientBoostingRegressor\nfrom sklearn.svm import SVR\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\nimport joblib","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import GradientBoostingRegressor\nfrom sklearn.svm import SVR\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\nimport joblib","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Check the data types of features and target variable\nprint(X.dtypes)\nprint(y.dtypes)\n\n# If your target variable is categorical, convert it to numeric if necessary\n# For example, if y is categorical, you can use label encoding\nfrom sklearn.preprocessing import LabelEncoder\n\n# If y is categorical, encode it\nif y.dtype == 'object':\n    le = LabelEncoder()\n    y = le.fit_transform(y)\n\n# If X contains categorical features, encode them\nX = pd.get_dummies(X, drop_first=True)  # One-hot encoding for categorical features","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Load and Preprocess Data","metadata":{}},{"cell_type":"code","source":"# Load your dataset\n# train_data = pd.read_csv('train_data.csv')  # Uncomment and replace with your actual data path\n\n# Assuming 'price' is the target variable and the rest are features\nX = train_data.drop(columns=['id', 'price'])\ny = train_data['price']\n\n# Split the data into training and test sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Decision Tree Regressor","metadata":{}},{"cell_type":"code","source":"# Assuming 'price' is the actual target variable you want to predict\ny = train_data['price']  # Use the actual price column for regression\n\n# Ensure that X contains only the feature columns\nX = train_data.drop(columns=['id', 'price', 'price_category'])  # Drop the target and any non-feature columns\n\n# Check the data types again\nprint(X.dtypes)\nprint(y.dtypes)\n\n# If X contains categorical features, encode them\nX = pd.get_dummies(X, drop_first=True)  # One-hot encoding for categorical features\n\n# Now split the data into training and test sets\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Now you can fit the Decision Tree model\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n\n# Initialize and train the Decision Tree Regressor\ndt_model = DecisionTreeRegressor(random_state=42)\ndt_model.fit(X_train, y_train)\n\n# Make predictions and evaluate\ndt_y_pred = dt_model.predict(X_test)\nprint(\"Decision Tree Regressor:\")\nprint(f\"MAE: {mean_absolute_error(y_test, dt_y_pred):.2f}\")\nprint(f\"MSE: {mean_squared_error(y_test, dt_y_pred):.2f}\")\nprint(f\"RÂ²: {r2_score(y_test, dt_y_pred):.2f}\")","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Gradient Boosting Regressor","metadata":{}},{"cell_type":"code","source":"from sklearn.impute import SimpleImputer\n\n# Create an imputer for numerical features\nimputer = SimpleImputer(strategy='mean')  # You can also use 'median' or 'most_frequent'\n\n# Fit the imputer on the training data and transform both training and test data\nX_train_imputed = imputer.fit_transform(X_train)\nX_test_imputed = imputer.transform(X_test)\n\n# Convert back to DataFrame if needed\nX_train = pd.DataFrame(X_train_imputed, columns=X.columns)\nX_test = pd.DataFrame(X_test_imputed, columns=X.columns)","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Initialize and train the Gradient Boosting Regressor\ngb_model = GradientBoostingRegressor(random_state=42)\ngb_model.fit(X_train, y_train)\n\n# Make predictions and evaluate\ngb_y_pred = gb_model.predict(X_test)\nprint(\"\\nGradient Boosting Regressor:\")\nprint(f\"MAE: {mean_absolute_error(y_test, gb_y_pred):.2f}\")\nprint(f\"MSE: {mean_squared_error(y_test, gb_y_pred):.2f}\")\nprint(f\"RÂ²: {r2_score(y_test, gb_y_pred):.2f}\")","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Support Vector Regression","metadata":{}},{"cell_type":"code","source":"# Initialize and train the Support Vector Regressor\nsvr_model = SVR(kernel='rbf')  # You can also try 'linear' or 'poly'\nsvr_model.fit(X_train, y_train)\n\n# Make predictions and evaluate\nsvr_y_pred = svr_model.predict(X_test)\nprint(\"\\nSupport Vector Regression:\")\nprint(f\"MAE: {mean_absolute_error(y_test, svr_y_pred):.2f}\")\nprint(f\"MSE: {mean_squared_error(y_test, svr_y_pred):.2f}\")\nprint(f\"RÂ²: {r2_score(y_test, svr_y_pred):.2f}\")","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Hyperparameter Tuning","metadata":{}},{"cell_type":"markdown","source":"Decision Trees","metadata":{}},{"cell_type":"code","source":"dt_param_grid = {\n    'max_depth': [None, 5, 10, 20],\n    'min_samples_split': [2, 5, 10]\n}\n\ndt_grid_search = GridSearchCV(DecisionTreeRegressor(random_state=42), dt_param_grid, cv=5, scoring='neg_mean_squared_error')\ndt_grid_search.fit(X_train, y_train)\n\nprint(\"\\nBest parameters for Decision Tree:\", dt_grid_search.best_params_)","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Gradient Boosting Hyperparameter Tuning","metadata":{}},{"cell_type":"code","source":"gb_param_grid = {\n    'n_estimators': [50, 100, 200],\n    'max_depth': [3, 5, 10],\n    'learning_rate': [0.01, 0.1, 0.2]\n}\n\ngb_grid_search = GridSearchCV(GradientBoostingRegressor(random_state=42), gb_param_grid, cv=5, scoring='neg_mean_squared_error')\ngb_grid_search.fit(X_train, y_train)\n\nprint(\"Best parameters for Gradient Boosting:\", gb_grid_search.best_params_)","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Support Vector Regression Hyperparameter Tuning","metadata":{}},{"cell_type":"code","source":"svr_param_grid = {\n    'C': [0.1, 1]\n}","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.model_selection import RandomizedSearchCV","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Define the parameter grid for RandomizedSearchCV\nparam_dist = {\n    'n_estimators': [50, 100, 200],\n    'max_depth': [3, 5, 10, None],\n    'learning_rate': [0.01, 0.1, 0.2],\n    'subsample': [0.8, 1.0],\n    'min_samples_split': [2, 5, 10]\n}","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Set up RandomizedSearchCV\nrandom_search = RandomizedSearchCV(\n    gb_model,\n    param_distributions=param_dist,\n    n_iter=100,  # Number of parameter settings to sample\n    cv=5,  # Number of cross-validation folds\n    scoring='neg_mean_squared_error',  # Use negative MSE for scoring\n    random_state=42,\n    n_jobs=-1  # Use all available cores\n)","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Fit the model using RandomizedSearchCV\nrandom_search.fit(X_train, y_train)\n","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Get the best model from the random search\nbest_model = random_search.best_estimator_\n","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Evaluate the model on the validation set\ny_val_pred = best_model.predict(X_test)\nmae = mean_absolute_error(y_test, y_val_pred)\nmse = mean_squared_error(y_test, y_val_pred)\nr2 = r2_score(y_test, y_val_pred)","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"Best parameters found: \", random_search.best_params_)\nprint(\"Evaluation on Test Set:\")\nprint(f\"Mean Absolute Error (MAE): {mae:.2f}\")\nprint(f\"Mean Squared Error (MSE): {mse:.2f}\")\nprint(f\"R-squared (RÂ²): {r2:.2f}\")","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Make predictions on the test set (if you have a separate test set)\n# Assuming you have a separate test set named 'test_data'\ntest_data = pd.read_csv('test.csv')  # Uncomment and replace with your actual test data path\nX_test_final = test_data.drop(columns=['id'])  # Adjust based on your test dataset","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Assuming you have already preprocessed your training data\n# For example, if you used one-hot encoding for categorical features in X_train:\nX_train = pd.get_dummies(X_train, drop_first=True)\nX_test_final = pd.get_dummies(X_test_final, drop_first=True)\n\n# Align the columns of X_test_final with X_train\nX_test_final = X_test_final.reindex(columns=X_train.columns, fill_value=0)\n\n# Now you can make predictions\ny_test_pred = best_model.predict(X_test_final)\n\n# Save predictions to a CSV file\nsample_submission = pd.DataFrame({'id': test_data['id'], 'price': y_test_pred})  # Adjust based on your test data\nsample_submission.to_csv('sample_submission.csv', index=False)","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Save the best model\njoblib.dump(best_model, 'best_gradient_boosting_model.pkl')","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{},"outputs":[],"execution_count":null}]}